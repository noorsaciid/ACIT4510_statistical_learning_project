{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8719ad86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sacii\\OneDrive\\Desktop\\Oslomet\\ACIT4510 Statistical learning\\ACIT4510_statistical_learning_project\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# 1. Imports\n",
    "# ==============================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4be5438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1920, 12) | Test: (600, 12) | Eval: (480, 12)\n"
     ]
    }
   ],
   "source": [
    "data_path = r\"C:\\Users\\sacii\\OneDrive\\Desktop\\Oslomet\\ACIT4510 Statistical learning\\ACIT4510_statistical_learning_project\\data\\raw\"\n",
    "\n",
    "train_df = pd.read_csv(fr\"{data_path}\\train_df.csv\")\n",
    "test_df = pd.read_csv(fr\"{data_path}\\test_df.csv\")\n",
    "eval_df = pd.read_csv(fr\"{data_path}\\eval_df.csv\")\n",
    "\n",
    "print(\"Train:\", train_df.shape, \"| Test:\", test_df.shape, \"| Eval:\", eval_df.shape)\n",
    "\n",
    "target_col = \"Happiness Score\"\n",
    "\n",
    "X_train = train_df.drop(columns=target_col).copy()\n",
    "y_train = train_df[target_col].copy()\n",
    "\n",
    "X_test = test_df.drop(columns=target_col).copy()\n",
    "y_test = test_df[target_col].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ac51624",
   "metadata": {},
   "outputs": [],
   "source": [
    "exercise_map = {\"Low\": 0.0, \"Moderate\": 0.5, \"High\": 1.0}\n",
    "diet_map = {\n",
    "    \"Junk Food\": 0.0,\n",
    "    \"Keto\": 0.5,\n",
    "    \"Vegetarian\": 0.7,\n",
    "    \"Vegan\": 0.9,\n",
    "    \"Balanced\": 1.0,\n",
    "}\n",
    "stress_map = {\"High\": 0.0, \"Moderate\": 0.5, \"Low\": 1.0}\n",
    "\n",
    "def add_engineered_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"Exercise_Num\"] = df[\"Exercise Level\"].map(exercise_map)\n",
    "    df[\"Diet_Num\"] = df[\"Diet Type\"].map(diet_map)\n",
    "    df[\"Stress_Num\"] = df[\"Stress Level\"].map(stress_map)\n",
    "\n",
    "    df[\"Sleep_exercise\"] = df[\"Sleep Hours\"] * df[\"Exercise_Num\"]\n",
    "    df[\"Healthy_index\"] = (df[\"Exercise_Num\"] + df[\"Diet_Num\"] + df[\"Stress_Num\"]) / 3.0\n",
    "    return df\n",
    "\n",
    "X_train_fe = add_engineered_features(X_train)\n",
    "X_test_fe = add_engineered_features(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e0175b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_xgb shape: (1920, 14)\n",
      "X_test_xgb  shape: (600, 14)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "numeric_features_xgb = [\n",
    "    \"Sleep Hours\",\n",
    "    \"Screen Time per Day (Hours)\",\n",
    "    \"Work Hours per Week\",\n",
    "    \"Social Interaction Score\",\n",
    "    \"Sleep_exercise\",\n",
    "    \"Healthy_index\",\n",
    "]\n",
    "\n",
    "categorical_features_xgb = [\"Exercise Level\", \"Diet Type\", \"Stress Level\"]\n",
    "\n",
    "ohe_only_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", \"passthrough\", numeric_features_xgb),\n",
    "        (\"cat\", OneHotEncoder(drop=\"first\", sparse_output=False), categorical_features_xgb),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "X_train_xgb = ohe_only_transformer.fit_transform(X_train_fe)\n",
    "X_test_xgb = ohe_only_transformer.transform(X_test_fe)\n",
    "\n",
    "X_train_xgb = X_train_xgb.astype(\"float32\")\n",
    "X_test_xgb = X_test_xgb.astype(\"float32\")\n",
    "\n",
    "print(\"X_train_xgb shape:\", X_train_xgb.shape)\n",
    "print(\"X_test_xgb  shape:\", X_test_xgb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2c8eb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 8),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 10.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "    }\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "        model = XGBRegressor(**params)\n",
    "\n",
    "        # Train on TRAIN\n",
    "        model.fit(X_train_xgb, y_train)\n",
    "\n",
    "        # Validate on TEST\n",
    "        y_pred = model.predict(X_test_xgb)\n",
    "\n",
    "        rmse = float(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        mae  = float(mean_absolute_error(y_test, y_pred))\n",
    "        r2   = float(r2_score(y_test, y_pred))\n",
    "\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics({\"rmse\": rmse, \"mae\": mae, \"r2\": r2})\n",
    "\n",
    "    return rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22f740e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-16 00:58:45,751] A new study created in memory with name: xgb_happiness_optuna_testset\n",
      "[I 2025-11-16 00:58:46,451] Trial 0 finished with value: 2.865516031271365 and parameters: {'n_estimators': 758, 'max_depth': 5, 'learning_rate': 0.06613216171036432, 'subsample': 0.6338707668470208, 'colsample_bytree': 0.6813336471522998, 'min_child_weight': 3, 'gamma': 1.8843892715888981, 'reg_alpha': 6.813824749654972e-07, 'reg_lambda': 2.1455406366811024e-05}. Best is trial 0 with value: 2.865516031271365.\n",
      "[I 2025-11-16 00:58:47,107] Trial 1 finished with value: 2.7776298924614657 and parameters: {'n_estimators': 810, 'max_depth': 6, 'learning_rate': 0.04484319350612686, 'subsample': 0.6858224152712168, 'colsample_bytree': 0.6896249760755115, 'min_child_weight': 9, 'gamma': 1.270049489993691, 'reg_alpha': 5.107827076840978, 'reg_lambda': 0.00019296230726206483}. Best is trial 1 with value: 2.7776298924614657.\n",
      "[I 2025-11-16 00:58:47,583] Trial 2 finished with value: 2.6974948036361055 and parameters: {'n_estimators': 232, 'max_depth': 8, 'learning_rate': 0.031368660142532805, 'subsample': 0.6374898374012842, 'colsample_bytree': 0.6790049034170046, 'min_child_weight': 8, 'gamma': 0.6627515397691924, 'reg_alpha': 2.2450328114750432e-07, 'reg_lambda': 2.9586352480127144e-07}. Best is trial 2 with value: 2.6974948036361055.\n",
      "[I 2025-11-16 00:58:48,190] Trial 3 finished with value: 2.674672807844331 and parameters: {'n_estimators': 896, 'max_depth': 7, 'learning_rate': 0.02610210995109038, 'subsample': 0.8283426260489284, 'colsample_bytree': 0.9257973891409325, 'min_child_weight': 3, 'gamma': 2.3162639581474247, 'reg_alpha': 2.3912508973247677, 'reg_lambda': 0.0021092965548953142}. Best is trial 3 with value: 2.674672807844331.\n",
      "[I 2025-11-16 00:58:48,625] Trial 4 finished with value: 2.6017096182193913 and parameters: {'n_estimators': 586, 'max_depth': 4, 'learning_rate': 0.013669835322370566, 'subsample': 0.8701444263727913, 'colsample_bytree': 0.704484757760203, 'min_child_weight': 4, 'gamma': 3.836136493722237, 'reg_alpha': 0.006921955188554951, 'reg_lambda': 0.003992828612680005}. Best is trial 4 with value: 2.6017096182193913.\n",
      "[I 2025-11-16 00:58:48,895] Trial 5 finished with value: 2.641491010152595 and parameters: {'n_estimators': 231, 'max_depth': 6, 'learning_rate': 0.05599612097237519, 'subsample': 0.9819144954047642, 'colsample_bytree': 0.8872914824191895, 'min_child_weight': 3, 'gamma': 1.8581815242030038, 'reg_alpha': 2.083605807309273e-07, 'reg_lambda': 0.00013630135542846248}. Best is trial 4 with value: 2.6017096182193913.\n",
      "[I 2025-11-16 00:58:49,196] Trial 6 finished with value: 2.7345594901958066 and parameters: {'n_estimators': 235, 'max_depth': 8, 'learning_rate': 0.07524865137658404, 'subsample': 0.793034404614195, 'colsample_bytree': 0.6447708029008756, 'min_child_weight': 2, 'gamma': 1.730914840880267, 'reg_alpha': 0.29603094426684073, 'reg_lambda': 0.00018439390266042845}. Best is trial 4 with value: 2.6017096182193913.\n",
      "[I 2025-11-16 00:58:49,704] Trial 7 finished with value: 2.8109101899058415 and parameters: {'n_estimators': 641, 'max_depth': 5, 'learning_rate': 0.05467861142859016, 'subsample': 0.7177891483720272, 'colsample_bytree': 0.6741636055553565, 'min_child_weight': 5, 'gamma': 1.633705089436358, 'reg_alpha': 2.9532376183653494e-07, 'reg_lambda': 0.05357235373376391}. Best is trial 4 with value: 2.6017096182193913.\n",
      "[I 2025-11-16 00:58:50,102] Trial 8 finished with value: 2.5922043081845065 and parameters: {'n_estimators': 413, 'max_depth': 5, 'learning_rate': 0.010441052348419681, 'subsample': 0.7354283500231061, 'colsample_bytree': 0.7344621474037165, 'min_child_weight': 8, 'gamma': 3.016171548872852, 'reg_alpha': 1.4259826441896777e-05, 'reg_lambda': 7.053791937513392e-05}. Best is trial 8 with value: 2.5922043081845065.\n",
      "[I 2025-11-16 00:58:50,589] Trial 9 finished with value: 2.737770481942511 and parameters: {'n_estimators': 639, 'max_depth': 7, 'learning_rate': 0.05269784102296023, 'subsample': 0.8809314496726881, 'colsample_bytree': 0.900005511293819, 'min_child_weight': 4, 'gamma': 1.0627076484703353, 'reg_alpha': 2.3083835383246175e-08, 'reg_lambda': 0.04574443155513503}. Best is trial 8 with value: 2.5922043081845065.\n",
      "[I 2025-11-16 00:58:50,932] Trial 10 finished with value: 2.828449218545401 and parameters: {'n_estimators': 419, 'max_depth': 3, 'learning_rate': 0.19549092221079353, 'subsample': 0.7642332962701958, 'colsample_bytree': 0.8050055571185357, 'min_child_weight': 7, 'gamma': 3.4250092328918536, 'reg_alpha': 8.168456547983672e-05, 'reg_lambda': 4.204017509157614}. Best is trial 8 with value: 2.5922043081845065.\n",
      "[I 2025-11-16 00:58:51,295] Trial 11 finished with value: 2.5708066621486463 and parameters: {'n_estimators': 432, 'max_depth': 3, 'learning_rate': 0.011214720931319094, 'subsample': 0.9091705575686873, 'colsample_bytree': 0.7710206698824025, 'min_child_weight': 10, 'gamma': 4.637013156646108, 'reg_alpha': 0.0022450836842314863, 'reg_lambda': 5.305992936571093e-07}. Best is trial 11 with value: 2.5708066621486463.\n",
      "[I 2025-11-16 00:58:51,645] Trial 12 finished with value: 2.5721151737895447 and parameters: {'n_estimators': 429, 'max_depth': 3, 'learning_rate': 0.010630650769606086, 'subsample': 0.9641862805769758, 'colsample_bytree': 0.7832177142711233, 'min_child_weight': 10, 'gamma': 4.972084216293542, 'reg_alpha': 0.00022442302219808242, 'reg_lambda': 1.4093019656548853e-08}. Best is trial 11 with value: 2.5708066621486463.\n",
      "[I 2025-11-16 00:58:52,004] Trial 13 finished with value: 2.5796868556675676 and parameters: {'n_estimators': 431, 'max_depth': 3, 'learning_rate': 0.017552681367142144, 'subsample': 0.9950066536324962, 'colsample_bytree': 0.8042716759255519, 'min_child_weight': 10, 'gamma': 4.9465890165255875, 'reg_alpha': 0.010559316344543875, 'reg_lambda': 1.7532280218954425e-08}. Best is trial 11 with value: 2.5708066621486463.\n",
      "[I 2025-11-16 00:58:52,438] Trial 14 finished with value: 2.581309715077181 and parameters: {'n_estimators': 514, 'max_depth': 4, 'learning_rate': 0.010038350612436124, 'subsample': 0.926988749865732, 'colsample_bytree': 0.7714379073095897, 'min_child_weight': 10, 'gamma': 4.911331268064819, 'reg_alpha': 0.0009964016152747043, 'reg_lambda': 9.728670185644763e-07}. Best is trial 11 with value: 2.5708066621486463.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================\n",
      "Best RMSE: 2.5708066621486463\n",
      "Best parameters:\n",
      "  n_estimators: 432\n",
      "  max_depth: 3\n",
      "  learning_rate: 0.011214720931319094\n",
      "  subsample: 0.9091705575686873\n",
      "  colsample_bytree: 0.7710206698824025\n",
      "  min_child_weight: 10\n",
      "  gamma: 4.637013156646108\n",
      "  reg_alpha: 0.0022450836842314863\n",
      "  reg_lambda: 5.305992936571093e-07\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 7. Run Optuna study with MLflow\n",
    "# ============================================\n",
    "mlflow_path = r\"C:\\Users\\sacii\\OneDrive\\Desktop\\Oslomet\\ACIT4510 Statistical learning\\ACIT4510_statistical_learning_project\\mlflow\"\n",
    "\n",
    "mlflow.set_tracking_uri(f\"file:///{mlflow_path}\")\n",
    "mlflow.set_experiment(\"xgboost_optuna_ACIT4510_statistical_learning_project\")\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    study_name=\"xgb_happiness_optuna_testset\"\n",
    ")\n",
    "study.optimize(objective, n_trials=15)\n",
    "\n",
    "print(\"\\n====================\")\n",
    "print(\"Best RMSE:\", study.best_value)\n",
    "print(\"Best parameters:\")\n",
    "for k, v in study.best_params.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(\"====================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f171b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acit4510-statistical-learning-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
